{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "OeWULuIqaDgF",
        "outputId": "e8dae88c-5cd7-48ca-a8c2-e646df360d62"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "partially initialized module 'torch._dynamo' has no attribute 'config' (most likely due to a circular import)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-c7a73bb0fdca>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, momentum, dampening, weight_decay, nesterov, maximize, foreach, differentiable, fused)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdampening\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Nesterov momentum requires a momentum and zero dampening\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;31m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mdisable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__dynamo_disable\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdisable_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mdisable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallback_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traceback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCapturedTraceback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_traceback_short\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbytecode_analysis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mremove_dead_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_pointless_jumps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m from .bytecode_transformation import (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/trace_rules.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   3216\u001b[0m         \u001b[0;34m\"torch.distributed._composable.replicate\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3217\u001b[0m     }\n\u001b[0;32m-> 3218\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_fsdp_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3219\u001b[0m         \u001b[0mLEGACY_MOD_INLINELIST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torch.distributed._composable.fsdp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'torch._dynamo' has no attribute 'config' (most likely due to a circular import)"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dataset = pd.read_csv('seattle-weather.csv')\n",
        "X = dataset.iloc[:, 1:-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "\n",
        "category_mapping = {category: idx for idx, category in enumerate(set(y), start=0)}\n",
        "\n",
        "y = [category_mapping[weather] for weather in y]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 0)\n",
        "\n",
        "sc = StandardScaler()\n",
        "train_data = sc.fit_transform(X_train)\n",
        "test_data = sc.transform(X_test)\n",
        "\n",
        "train_data, train_labels = torch.tensor(train_data).float(), torch.tensor(y_train)\n",
        "test_data, test_labels = torch.tensor(test_data).float(), torch.tensor(y_test)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 16)\n",
        "        self.fc2 = nn.Linear(16, 8)\n",
        "        self.fc3 = nn.Linear(8, 5)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = MLP()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-3)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=10)\n",
        "\n",
        "patience = 20\n",
        "best_loss = float('inf')\n",
        "counter = 0\n",
        "\n",
        "selected_epochs = []\n",
        "selected_losses = []\n",
        "\n",
        "prev_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "num_epochs = 5000\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    outputs = model(train_data)\n",
        "    loss = criterion(outputs, train_labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss = loss.item()\n",
        "\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    if current_lr != prev_lr:\n",
        "        print(f\"Το learning rate άλλαξε από {prev_lr:.6f} σε {current_lr:.6f} στο τέλος της εποχής {epoch}\")\n",
        "        prev_lr = current_lr\n",
        "\n",
        "    if (epoch + 1) <= 20 or (epoch + 1) % 50 == 0:\n",
        "        selected_epochs.append(epoch + 1)\n",
        "        selected_losses.append(epoch_loss)\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    scheduler.step(epoch_loss)\n",
        "\n",
        "    if epoch_loss < best_loss:\n",
        "        best_loss = epoch_loss\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= patience:\n",
        "            if (epoch + 1) not in selected_epochs:\n",
        "              selected_epochs.append(epoch + 1)\n",
        "              selected_losses.append(epoch_loss)\n",
        "            print(f\"Early stopping at epoch {epoch + 1}, Loss: {epoch_loss:.4f}\")\n",
        "            break\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Χρόνος εκπαίδευσης: {(end_time - start_time) / 60:.2f} λεπτά\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(selected_epochs, selected_losses, label=\"Selected Loss\", marker='o')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss σε Επιλεγμένες Εποχές\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "model.eval()\n",
        "\n",
        "def predict_acc(data, labels, name):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        accuracy = 100 * correct / labels.size(0)\n",
        "\n",
        "    print(f'Ακρίβεια στο {name} set: {accuracy:.2f}%')\n",
        "\n",
        "    return predicted\n",
        "\n",
        "predict_acc(train_data, train_labels, \"Training\")\n",
        "predicted = predict_acc(test_data, test_labels, \"Test\")\n",
        "\n",
        "def accuracy_per_category(test_labels, predicted, label_names):\n",
        "    class_correct = []\n",
        "    class_total = []\n",
        "\n",
        "    for i in range(5):\n",
        "        class_correct.append(0)\n",
        "        class_total.append(0)\n",
        "\n",
        "    for i in range(len(test_labels)):\n",
        "        label = test_labels[i]\n",
        "        class_total[label] += 1\n",
        "        if predicted[i].item() == label:\n",
        "            class_correct[label] += 1\n",
        "\n",
        "    for i in range(5):\n",
        "        if class_total[i] > 0:\n",
        "          accuracy = 100 * class_correct[i] / class_total[i]\n",
        "        else:\n",
        "            accuracy = 0\n",
        "        print(f\"Κατηγορία: {label_names[i]:<10s} | Σωστά: {class_correct[i]:<3} / {class_total[i]:<3} | Ακρίβεια: {accuracy:.2f}%\")\n",
        "\n",
        "label_names =['snow', 'rain', 'fog', 'drizzle', 'sun']\n",
        "accuracy_per_category(test_labels, predicted, label_names)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install seaborn"
      ],
      "metadata": {
        "id": "OMwYBycUwaau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "program_start_time = time.time()\n",
        "\n",
        "dataset = pd.read_csv('seattle-weather.csv')\n",
        "X = dataset.iloc[:, 1:-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "category_mapping = {category: idx for idx, category in enumerate(set(y), start=0)}\n",
        "\n",
        "y = [category_mapping[weather] for weather in y]\n",
        "\n",
        "print(\"Αντιστοίχιση κατηγοριών:\", category_mapping)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
        "\n",
        "sc = StandardScaler()\n",
        "train_data = sc.fit_transform(X_train)\n",
        "test_data = sc.transform(X_test)\n",
        "\n",
        "label_names = ['drizzle', 'rain', 'fog', 'snow', 'sun']\n",
        "\n",
        "def accuracy_per_category(test_labels, predicted, label_names):\n",
        "    class_correct = [0] * len(label_names)\n",
        "    class_total = [0] * len(label_names)\n",
        "\n",
        "    for i in range(len(test_labels)):\n",
        "        label = test_labels[i]\n",
        "        class_total[label] += 1\n",
        "        if predicted[i] == label:\n",
        "            class_correct[label] += 1\n",
        "\n",
        "    for i in range(len(label_names)):\n",
        "        accuracy = 100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0\n",
        "        print(f\"Κατηγορία: {label_names[i]:<10s} | Σωστά: {class_correct[i]:<3} / {class_total[i]:<3} | Ακρίβεια: {accuracy:.2f}%\")\n",
        "\n",
        "parameters = {\n",
        "    'C': [100.0, 300.0, 500.0, 1000.0],\n",
        "    'gamma': [0.002, 0.005, 0.01, 0.02, 0.05, 0.1],\n",
        "}\n",
        "\n",
        "model = SVC()\n",
        "clf = GridSearchCV(estimator=model, param_grid=parameters, cv=10, scoring='accuracy')\n",
        "clf.fit(train_data, y_train)\n",
        "\n",
        "print(\"Best parameters set found on development set:\")\n",
        "print(clf.best_params_)\n",
        "\n",
        "model = SVC(kernel='rbf', C=clf.best_params_['C'], gamma=clf.best_params_['gamma'])\n",
        "model.fit(train_data, y_train)\n",
        "\n",
        "predictions_train = model.predict(train_data)\n",
        "predictions_test = model.predict(test_data)\n",
        "\n",
        "print(f\"Accuracy στο Training Set: {accuracy_score(y_true=y_train, y_pred=predictions_train)*100:.2f}%\")\n",
        "print(f\"Accuracy στο Test Set: {accuracy_score(y_true=y_test, y_pred=predictions_test)*100:.2f}%\")\n",
        "\n",
        "accuracy_per_category(y_test, predictions_test, label_names)\n",
        "\n",
        "program_end_time = time.time()\n",
        "print(f\"Χρόνος εκτέλεσης προγράμματος: {(program_end_time - program_start_time) / 60:.2f} λεπτά\")"
      ],
      "metadata": {
        "id": "o8SWrWAQxcsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "program_start_time = time.time()\n",
        "\n",
        "dataset = pd.read_csv('seattle-weather.csv')\n",
        "X = dataset.iloc[:, 1:-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "category_mapping = {category: idx for idx, category in enumerate(set(y), start=0)}\n",
        "\n",
        "y = [category_mapping[weather] for weather in y]\n",
        "\n",
        "print(\"Αντιστοίχιση κατηγοριών:\", category_mapping)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
        "\n",
        "sc = StandardScaler()\n",
        "train_data = sc.fit_transform(X_train)\n",
        "test_data = sc.transform(X_test)\n",
        "\n",
        "label_names = ['drizzle', 'rain', 'fog', 'snow', 'sun']\n",
        "\n",
        "classifier = LogisticRegression(random_state = 0, max_iter=1000)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "yy = classifier.predict(X_train)\n",
        "cm = confusion_matrix(y_train, yy)\n",
        "print(cm)\n",
        "print(f\"Training set Accuracy: {accuracy_score(y_train, yy)*100:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "print(f\"Test set Accuracy: {accuracy_score(y_test, y_pred)*100:.2f}%\")"
      ],
      "metadata": {
        "id": "Pjv4Nionh6_-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}